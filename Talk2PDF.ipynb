{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424ea396-8d6a-4da2-a7f1-8d64a8d485cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c6f9cb-a22b-4493-81a3-2d4a2354a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99283871-2154-4f3d-8d7b-77b2cce3c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file):\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    print(f'Loading {file}')\n",
    "    loader = PyPDFLoader(file)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f3318d-6e05-42de-9357-cda9d38723cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./test.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='', metadata={'source': './test.pdf', 'page': 0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the load_pdf function on test.pdf\n",
    "data = load_pdf('./test.pdf')\n",
    "\n",
    "#print(data[5].page_content)\n",
    "#print(data[10].metadata)\n",
    "#print(f'There are {len(data)} pages in your PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed210f7-1501-4785-8f15-0893e78d44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc969f54-d3aa-45da-a6f5-95f7a691a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing chunk_data function on test.pdf \n",
    "chunks = chunk_data(data)\n",
    "#print(len(chunks))\n",
    "#print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059412c3-688f-4184-9610-c1f8074f0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Embedding and Uploading to Vector Database (Pinecone)\n",
    "\n",
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import ServerlessSpec\n",
    "\n",
    "    pc = pinecone.Pinecone()\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists!')\n",
    "        print('Loading embeddings')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Embeddings successfully loaded!')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings...')\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Embeddings successfully loaded!')\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2884abd-b46e-43b3-a99f-88b5ebbc9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting indexes from Pinecone\n",
    "\n",
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc = pinecone.Pinecone()\n",
    "    if index_name=='all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        print('Deleting all indexes')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name}')\n",
    "        pc.delete_index(index_name)\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73532f38-8e4e-4885-bd7f-eed908db20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Testing the embeddings and deleting_index functions:\n",
    "\n",
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f98f2f2-a41d-430f-ae4d-2d15a6cacb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index talk2pdf already exists!\n",
      "Loading embeddings\n",
      "Embeddings successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "index_name = 'talk2pdf'\n",
    "vector_store = insert_or_fetch_embeddings(index_name, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a36a89-52d4-40f2-b52c-57bb9302c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking and Getting Answers\n",
    "\n",
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)\n",
    "    answer = chain.run(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe89804-ecc2-4103-9be8-ed910b3580a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Ask me anything about your PDF!')\n",
    "print('Write ''Exit'' to quit')\n",
    "while True:\n",
    "    q = input(f'Question {i}: ')\n",
    "    i+=1\n",
    "    if q.lower() == 'exit':\n",
    "        print('Exited Successfully!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f'\\nAnswer: {answer}')\n",
    "    print(f'\\n {\"-\" *50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5037961c-076c-4c44-afa5-2354097ccb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Memory\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af14265-595b-4ad6-ba6b-bb7cf5dffd11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
